{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8936fc14",
   "metadata": {},
   "source": [
    "#### Lab 2 — Data Collection & Pre-Processing\n",
    "**Student:** Albright Maduka  \n",
    "\n",
    "**Course:** PROG8245 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feecdda",
   "metadata": {},
   "source": [
    "#### Lab Assignment\n",
    "##### You will execute the 12-step Data Engineering road-map practiced in class, this time end-to-end on a realistic e-commerce dataset.\n",
    "##### Your deliverable is a well-commented Jupyter Notebook that loads raw data, cleans and enriches it, and finishes with a concise analytical insight. All code, data, and documentation must live in a GitHub repository you control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e292a69",
   "metadata": {},
   "source": [
    "### 1. Hello, Data!\n",
    "\n",
    "Aim: Load raw CSV and display first 3 rows\n",
    "\n",
    "Reason: It ensure that my dataset is read and loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "954afceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Region Country   Item Type Sales Channel  \\\n",
      "0  Middle East and North Africa   Libya   Cosmetics       Offline   \n",
      "1                 North America  Canada  Vegetables        Online   \n",
      "2  Middle East and North Africa   Libya   Baby Food       Offline   \n",
      "\n",
      "  Order Priority  Order Date   Order ID   Ship Date  Units Sold  Unit Price  \\\n",
      "0              M  10/18/2014  686800706  10/31/2014        8446      437.20   \n",
      "1              M   11/7/2011  185941302   12/8/2011        3018      154.06   \n",
      "2              C  10/31/2016  246222341   12/9/2016        1517      255.28   \n",
      "\n",
      "   Unit Cost  Total Revenue  Total Cost  Total Profit  \n",
      "0     263.33     3692591.20  2224085.18    1468506.02  \n",
      "1      90.93      464953.08   274426.74     190526.34  \n",
      "2     159.42      387259.76   241840.14     145419.62  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv(r\"data\\1000 Sales Records.csv\")\n",
    "\n",
    "print(data.head(3)) # Display the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed6758",
   "metadata": {},
   "source": [
    "#### 2. Pick the Right Container\n",
    "Aim: Dict vs namedtuple vs set (1–2 sentences).\n",
    "\n",
    "Reason: Dict is used for deciding how to store data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b39c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict is for mapping keys to values, allowing for flexible and dynamic data storage.\n",
    "# Namedtuple is for creating lightweight, immutable objects with named fields, providing better structure and readability\n",
    "# Set is for storing unique products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade489de",
   "metadata": {},
   "source": [
    "#### 3. Implement Functions and Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14176df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Transaction = namedtuple('Transaction', ['date', 'customer_id', 'product', 'price', 'quantity', 'coupon_code', 'shipping_city'])\n",
    "\n",
    "def clean(row):\n",
    "    return Transaction(\n",
    "        date=row['Order Date'],\n",
    "        customer_id=row['customer_id'],\n",
    "        product=row['Item Type'],\n",
    "        price=row['Unit Price'],\n",
    "        quantity=row['Units Sold'],\n",
    "        coupon_code=row['coupon_code'],\n",
    "        shipping_city=row['shipping_city']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cfb9562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Region          1000 non-null   object \n",
      " 1   Country         1000 non-null   object \n",
      " 2   Item Type       1000 non-null   object \n",
      " 3   Sales Channel   1000 non-null   object \n",
      " 4   Order Priority  1000 non-null   object \n",
      " 5   Order Date      1000 non-null   object \n",
      " 6   Order ID        1000 non-null   int64  \n",
      " 7   Ship Date       1000 non-null   object \n",
      " 8   Units Sold      1000 non-null   int64  \n",
      " 9   Unit Price      1000 non-null   float64\n",
      " 10  Unit Cost       1000 non-null   float64\n",
      " 11  Total Revenue   1000 non-null   float64\n",
      " 12  Total Cost      1000 non-null   float64\n",
      " 13  Total Profit    1000 non-null   float64\n",
      "dtypes: float64(5), int64(2), object(7)\n",
      "memory usage: 109.5+ KB\n",
      "None\n",
      "Data Description:\n",
      "        Region Country  Item Type Sales Channel Order Priority Order Date  \\\n",
      "count     1000    1000       1000          1000           1000       1000   \n",
      "unique       7     185         12             2              4        841   \n",
      "top     Europe    Cuba  Beverages       Offline              L  7/19/2010   \n",
      "freq       267      11        101           520            268          3   \n",
      "mean       NaN     NaN        NaN           NaN            NaN        NaN   \n",
      "std        NaN     NaN        NaN           NaN            NaN        NaN   \n",
      "min        NaN     NaN        NaN           NaN            NaN        NaN   \n",
      "25%        NaN     NaN        NaN           NaN            NaN        NaN   \n",
      "50%        NaN     NaN        NaN           NaN            NaN        NaN   \n",
      "75%        NaN     NaN        NaN           NaN            NaN        NaN   \n",
      "max        NaN     NaN        NaN           NaN            NaN        NaN   \n",
      "\n",
      "            Order ID Ship Date   Units Sold  Unit Price    Unit Cost  \\\n",
      "count   1.000000e+03      1000  1000.000000  1000.00000  1000.000000   \n",
      "unique           NaN       835          NaN         NaN          NaN   \n",
      "top              NaN  6/8/2011          NaN         NaN          NaN   \n",
      "freq             NaN         3          NaN         NaN          NaN   \n",
      "mean    5.496813e+08       NaN  5053.988000   262.10684   184.965110   \n",
      "std     2.571334e+08       NaN  2901.375317   216.02106   175.289311   \n",
      "min     1.029280e+08       NaN    13.000000     9.33000     6.920000   \n",
      "25%     3.280740e+08       NaN  2420.250000    81.73000    56.670000   \n",
      "50%     5.566097e+08       NaN  5184.000000   154.06000    97.440000   \n",
      "75%     7.696945e+08       NaN  7536.750000   421.89000   263.330000   \n",
      "max     9.955298e+08       NaN  9998.000000   668.27000   524.960000   \n",
      "\n",
      "        Total Revenue    Total Cost  Total Profit  \n",
      "count    1.000000e+03  1.000000e+03  1.000000e+03  \n",
      "unique            NaN           NaN           NaN  \n",
      "top               NaN           NaN           NaN  \n",
      "freq              NaN           NaN           NaN  \n",
      "mean     1.327322e+06  9.361192e+05  3.912026e+05  \n",
      "std      1.486515e+06  1.162571e+06  3.836402e+05  \n",
      "min      2.043250e+03  1.416750e+03  5.326100e+02  \n",
      "25%      2.811919e+05  1.649319e+05  9.837612e+04  \n",
      "50%      7.549392e+05  4.647261e+05  2.772260e+05  \n",
      "75%      1.733503e+06  1.141750e+06  5.484568e+05  \n",
      "max      6.617210e+06  5.204978e+06  1.726181e+06  \n"
     ]
    }
   ],
   "source": [
    "print(\"Data Info:\")\n",
    "print(data.info()) # This is used to display summary of the DataFrame  \n",
    "\n",
    "print(\"Data Description:\")\n",
    "print(data.describe(include='all')) # Generate or describe statistics that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbdc1e",
   "metadata": {},
   "source": [
    "#### 3 Cleaning\n",
    "It is the process of cleaning missing values, correcting typos and also ensuring numerical columns are correctly inputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aeb4e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "Region            0\n",
      "Country           0\n",
      "Item Type         0\n",
      "Sales Channel     0\n",
      "Order Priority    0\n",
      "Order Date        0\n",
      "Order ID          0\n",
      "Ship Date         0\n",
      "Units Sold        0\n",
      "Unit Price        0\n",
      "Unit Cost         0\n",
      "Total Revenue     0\n",
      "Total Cost        0\n",
      "Total Profit      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values in the dataset 0 means no missing values\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# isnull() function is used to detect missing values in a DataFrame. It returns a DataFrame of the same shape as the original, with boolean values indicating whether each element is missing (True) or not (False). \n",
    "# The sum() function is then applied to count the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66d2487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Region          1000 non-null   object \n",
      " 1   Country         1000 non-null   object \n",
      " 2   Item Type       1000 non-null   object \n",
      " 3   Sales Channel   1000 non-null   object \n",
      " 4   Order Priority  1000 non-null   object \n",
      " 5   Order Date      1000 non-null   object \n",
      " 6   Order ID        1000 non-null   int64  \n",
      " 7   Ship Date       1000 non-null   object \n",
      " 8   Units Sold      1000 non-null   int64  \n",
      " 9   Unit Price      1000 non-null   float64\n",
      " 10  Unit Cost       1000 non-null   float64\n",
      " 11  Total Revenue   1000 non-null   float64\n",
      " 12  Total Cost      1000 non-null   float64\n",
      " 13  Total Profit    1000 non-null   float64\n",
      "dtypes: float64(5), int64(2), object(7)\n",
      "memory usage: 109.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates if any\n",
    "data = data.drop_duplicates()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10e62a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df): # Function to clean the dataset\n",
    "    df = df.drop_duplicates() # Remove duplicates if any\n",
    "    df = df.dropna(subset=['Order ID', 'Order Date', 'Ship Date', 'Sales']) # Drop rows with missing critical values\n",
    "    df['Item Type'] = df['Item Type'].str.strip()\n",
    "    df['Country'] = df['Country'].str.strip()\n",
    "    df['Order Date'] = pd.to_datetime(df['Order Date']) # Convert to datetime\n",
    "    df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
    "    if 'Coupon Code' in df.columns:\n",
    "        df['Coupon Code'] = df['Coupon Code'].fillna('None') # Fill missing coupon codes with 'None'\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8254284d",
   "metadata": {},
   "source": [
    "Reason: It's the process of cleaning raw data\n",
    "i. I removed duplicates\n",
    "ii. I removed the rows with missing values\n",
    "iii. I removed the spaces\n",
    "iv. converted dates to time\n",
    "v. filled the missing coupon codes with none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f955c",
   "metadata": {},
   "source": [
    "#### 4. Bulk Loaded\n",
    "Markdown: Explain how you mapped raw data into structured objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87fedc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m data = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m1000 Sales Records.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m transactions = [clean(row) \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m.iterrows()]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "transactions = [clean(row) for _, row in df.iterrows()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4da5d4",
   "metadata": {},
   "source": [
    "5. Quick Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d52653e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMin price:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mUnit Price\u001b[39m\u001b[33m'\u001b[39m].min())\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMean price:\u001b[39m\u001b[33m\"\u001b[39m, df[\u001b[33m'\u001b[39m\u001b[33mUnit Price\u001b[39m\u001b[33m'\u001b[39m].mean())\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMax price:\u001b[39m\u001b[33m\"\u001b[39m, df[\u001b[33m'\u001b[39m\u001b[33mUnit Price\u001b[39m\u001b[33m'\u001b[39m].max())\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Min price:\", df['Unit Price'].min())\n",
    "print(\"Mean price:\", df['Unit Price'].mean())\n",
    "print(\"Max price:\", df['Unit Price'].max())\n",
    "print(\"Unique cities:\", len(set(df['shipping_city'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
