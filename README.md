# lab2_data_collection_and_pre-processing
This Lab shows a 12 steps data engineering road map on a real life e-commerce dataset.
I used 1000_Sales_Records dataset as my primary dataset and added more metadata from the world cities which was my secondary dataset.
In addition, the jupyter note book show a 12 steps roadmap: Ingestion, profiling, cleaning, transforming, feature engineering and serialing data.
finally, the output is cleaned, merged data dictionary save in both CSV and JSON fmt.
Quick-start
In the bash terminal
python -m venv venv
pip install -r requirements.txt
jupyter notebook
Data sources
primary dataset: https://excelbianalytics.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/
secondary dataset:https://simplemaps.com/data/world-cities?utm_source=chatgpt.com

